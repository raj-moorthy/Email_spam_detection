# -*- coding: utf-8 -*-
"""email_spam_detection.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1i-l1bKDhCrFr-r9pG0rW6HVD0zXBIiJu
"""

import numpy as np                 #importing necessarry libraries
import matplotlib.pyplot as plt
from sklearn.feature_extraction.text import TfidfVectorizer
import pandas as pd
data = pd.read_csv('/content/drive/MyDrive/spam.csv', encoding='latin-1')   #loading the dataset which downloaded from given datasets
data

from google.colab import drive
drive.mount('/content/drive')

# Data exploration (optional)
print(data.head())  # Display the first few rows

print(data.columns)#accessing the columns

# Clean up the dataset by selecting only relevant columns if they exist
if 'v1' in data.columns and 'v2' in data.columns:
    data = data[['v1', 'v2']]  # Selecting only 'v1' (label) and 'v2' (email content)
    data.columns = ['Label', 'Email']  # Renaming columns to 'Label' and 'Email'

data

# Convert labels to binary values: 'spam' to 1 and 'ham' (not spam) to 0
data['Label'] = data['Label'].map({'spam': 1, 'ham': 0})
data

from re import X
# Splitting dataset into features (X) and target (y)
x = data['Email']
y = data['Label']
x

y

# Split data into training and testing sets
from sklearn.model_selection import train_test_split
x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)
x_train

y_test

# Vectorize the text data using CountVectorizer (Bag-of-Words model)
from sklearn.feature_extraction.text import CountVectorizer# vectorization is a key step in feature extraction that converts text data into vectors to train machine learning algorithms.
vectorizer = CountVectorizer(stop_words='english')  # Remove common English stop words
x_train_vec = vectorizer.fit_transform(x_train)
x_test_vec = vectorizer.transform(x_test)
x_train_vec



# Initialize the Naive Bayes model
from sklearn.naive_bayes import MultinomialNB #Naive Bayes is a statistical classification technique that uses Bayes' Theorem to predict the probability of an event based on a set of features
model = MultinomialNB()
# Train the model
model.fit(x_train_vec, y_train)

# Make predictions on the test set
y_pred_nb = model.predict(x_test_vec)
y_pred_nb

# Evaluate the model's performance
from sklearn.metrics import accuracy_score
accuracy_nb = accuracy_score(y_test, y_pred_nb)
print(f"Accuracy: {accuracy_nb * 100:.2f}%")

# Confusion Matrix
from sklearn.metrics import confusion_matrix
conf_matrix = confusion_matrix(y_test, y_pred_nb)
print("Confusion Matrix:")
print(conf_matrix)

# Classification Report
from sklearn.metrics import classification_report
print("Classification Report:")
print(classification_report(y_test, y_pred_nb))

# Test the model on a new email
def predict_spam(email_text):
    email_vec = vectorizer.transform([email_text])  # Transform the email into the same vector space
    prediction = model.predict(email_vec)
    return "Spam" if prediction[0] == 1 else "Not Spam"

# Example email
new_email = "Congratulations! You've won a free vacation to the Bahamas. Call now to claim your prize."
print("New Email Prediction:")
print(predict_spam(new_email))

data_cleaned = data.dropna()

print(data_cleaned.columns)

# Step 1: Vectorize the text using TF-IDF
tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X = tfidf.fit_transform(data_cleaned['Email']).toarray()

# Step 2: Define labels
y = data_cleaned['Label']

# Step 3: Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

from sklearn.tree import DecisionTreeClassifier
dt_model = DecisionTreeClassifier(random_state=42)
dt_model.fit(X_train, y_train)
y_pred_dt = dt_model.predict(X_test)
accuracy_dt = accuracy_score(y_test, y_pred_dt)
accuracy_dt

# Step 4: Train the Random Forest model
from sklearn.ensemble import RandomForestClassifier
rf_model = RandomForestClassifier(n_estimators=100, random_state=42)
rf_model.fit(X_train, y_train)

# Step 5: Make predictions and evaluate the model
y_pred = rf_model.predict(X_test)

accuracy = accuracy_score(y_test, y_pred)
report = classification_report(y_test, y_pred)

# Output results
print(f"Accuracy: {accuracy * 100:.2f}%")
print("Classification Report:\n", report)

# Function to check if a new email is spam or not
def predict_email_spam(email_text):
    # Preprocess the new email using the same TF-IDF vectorizer
    email_tfidf = tfidf.transform([email_text]).toarray()

    # Predict using the trained Random Forest model
    prediction = rf_model.predict(email_tfidf)

    # Convert prediction to human-readable format
    return 'Spam' if prediction[0] == 1 else 'Ham'

# Example new email
new_email = "Congratulations! You've won a $1000 gift card. Click here to claim your prize."
result = predict_email_spam(new_email)

print(f"The new email is classified as: {result}")

"""Logistic regression"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import classification_report, accuracy_score

data = pd.read_csv("/content/drive/MyDrive/spam.csv", encoding='latin1')
data

data_cleaned = data[['v1', 'v2']].copy()
data_cleaned.columns = ['label', 'message']

data_cleaned['label'] = data_cleaned['label'].map({'ham': 0, 'spam': 1})

tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X = tfidf.fit_transform(data_cleaned['message']).toarray()

y = data_cleaned['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

lr_model = LogisticRegression(max_iter=1000, random_state=42)
lr_model.fit(X_train, y_train)

y_pred_lr = lr_model.predict(X_test)

accuracy_lr = accuracy_score(y_test, y_pred_lr)
report_lr = classification_report(y_test, y_pred_lr)

print(f"Logistic Regression Accuracy: {accuracy_lr * 100:.2f}%")
print("Logistic Regression Classification Report:\n", report_lr)

# Function to check if a new email is spam or not
def predict_email_spam(email_text):
    # Preprocess the new email using the same TF-IDF vectorizer
    email_tfidf = tfidf.transform([email_text]).toarray()

    # Predict using the trained Logistic Regression model
    prediction = lr_model.predict(email_tfidf)

    # Convert prediction to human-readable format
    return 'Spam' if prediction[0] == 1 else 'Ham'

# Example new email
new_email = "Hey, just wanted to check if we are still on for dinner tonight. Let me know!"
result = predict_email_spam(new_email)

print(f"The new email is classified as: {result}")

"""knn

"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.neighbors import KNeighborsClassifier
from sklearn.metrics import classification_report, accuracy_score

data = pd.read_csv("/content/drive/MyDrive/spam.csv", encoding='latin1')
data

data_cleaned = data[['v1', 'v2']].copy()
data_cleaned.columns = ['label', 'message']

data_cleaned['label'] = data_cleaned['label'].map({'ham': 0, 'spam': 1})

tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X = tfidf.fit_transform(data_cleaned['message']).toarray()

y = data_cleaned['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

knn_model = KNeighborsClassifier(n_neighbors=5)
knn_model.fit(X_train, y_train)

y_pred_knn = knn_model.predict(X_test)

accuracy_knn = accuracy_score(y_test, y_pred_knn)
report_knn = classification_report(y_test, y_pred_knn)

print(f"KNN Accuracy: {accuracy_knn * 100:.2f}%")
print("KNN Classification Report:\n", report_knn)

# Optional: Function to check if a new email is spam or not
def predict_email_spam_knn(email_text):
    # Preprocess the new email using the same TF-IDF vectorizer
    email_tfidf = tfidf.transform([email_text]).toarray()

    # Predict using the trained KNN model
    prediction = knn_model.predict(email_tfidf)

    # Convert prediction to human-readable format
    return 'Spam' if prediction[0] == 1 else 'Ham'

# Example new email
new_email = "Get a chance to win an iPhone by participating in our survey. Click here now to enter!"
result = predict_email_spam_knn(new_email)

print(f"The new email is classified as: {result}")

"""SVM"""

import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.svm import SVC
from sklearn.metrics import classification_report, accuracy_score, confusion_matrix
import seaborn as sns
import matplotlib.pyplot as plt

data = pd.read_csv("/content/drive/MyDrive/spam.csv", encoding='latin1')
data

data_cleaned = data[['v1', 'v2']].copy()
data_cleaned.columns = ['label', 'message']

data_cleaned['label'] = data_cleaned['label'].map({'ham': 0, 'spam': 1})

tfidf = TfidfVectorizer(stop_words='english', max_features=3000)
X = tfidf.fit_transform(data_cleaned['message']).toarray()

y = data_cleaned['label']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

svm_model = SVC(kernel='linear', random_state=42)
svm_model.fit(X_train, y_train)

y_pred_svm = svm_model.predict(X_test)

accuracy_svm = accuracy_score(y_test, y_pred_svm)
report_svm = classification_report(y_test, y_pred_svm)

print(f"SVM Accuracy: {accuracy_svm * 100:.2f}%")
print("SVM Classification Report:\n", report_svm)

conf_matrix_svm = confusion_matrix(y_test, y_pred_svm)

# Display the confusion matrix as a heatmap
sns.heatmap(conf_matrix_svm, annot=True, fmt="d", cmap="Blues", xticklabels=['Ham', 'Spam'], yticklabels=['Ham', 'Spam'])
plt.ylabel('Actual')
plt.xlabel('Predicted')
plt.title('Confusion Matrix for SVM Model')
plt.show()

"""XGBOOST"""

from xgboost import XGBClassifier
xgb= XGBClassifier()
xgb.fit(X_train,y_train)
y_pred_xgb=xgb.predict(X_test)

accuracy_xgb=accuracy_score(y_test,y_pred_xgb)
report_xgb=classification_report(y_test,y_pred_xgb)
accuracy_xgb

table={'Model':['Logistic Regression','SVM','KNN','Random Forest','Decision Tree','Naive Bayes','XGBoost'],
       'Accuracy':[accuracy_lr,accuracy_svm,accuracy_knn,accuracy,accuracy_dt,accuracy_nb,accuracy_xgb]}
table=pd.DataFrame(table)
table

import pickle

with open('model.pkl', 'wb') as file:
    pickle.dump(model, file)

print("Naive Bayes model has been saved to 'model.pkl'")

with open('model.pkl', 'rb') as file:
    loaded_model = pickle.load(file)